{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475f9bfc-5ff6-41f0-ae9c-1b507fa01db1",
   "metadata": {},
   "source": [
    "# US-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "290ff132-80eb-48fc-9b88-5797260b1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994cc27-eaa6-46bb-92cb-6e67e46fea62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Camus Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6787f-2581-41cc-ba27-d833faa59ca1",
   "metadata": {},
   "source": [
    "Just to remind myself that \\*.raw and \\*.mhd files contain the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0174e4fc-6db4-42d4-89c0-f1628bcfb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@tf.function\n",
    "def read_raw_image(image_path):\n",
    "    imgfile = tf.io.read_file(image_path)\n",
    "    imgbytes = tf.io.decode_raw(imgfile, out_type=tf.uint8)\n",
    "    img = tf.reshape(imgbytes, (778, 549))\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_raw_seq(image_path):\n",
    "    imgfile = tf.io.read_file(image_path)\n",
    "    imgbytes = tf.io.decode_raw(imgfile, out_type=tf.uint8)\n",
    "    img = tf.reshape(imgbytes, (-1, 778, 549))\n",
    "    return img\n",
    "\n",
    "\n",
    "def play_sequence(sequence_array):\n",
    "    cap = cv2.VideoCapture()\n",
    "    has_frames = True\n",
    "    frame_counter = 0\n",
    "    while True:\n",
    "        frame = sequence_array[frame_counter, :, :]\n",
    "        cv2.imshow('frame',frame)\n",
    "        time.sleep(0.1)\n",
    "        frame_counter+=1\n",
    "        if frame_counter==sequence_array.shape[0]:\n",
    "            frame_counter = 0\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "seq = read_raw_seq(r'patient0001/patient0001_4CH_sequence.raw')\n",
    "#plt.imshow(img, 'gray')\n",
    "play_sequence(seq.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795e70c",
   "metadata": {},
   "source": [
    "# Now that we know how to read images and masks, we will process their addresses, and then use tf.data to build the input pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dabf993b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m         train_targets\u001b[38;5;241m.\u001b[39mappend(file_path)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(train_inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_targets)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "\n",
    "\n",
    "DATASET_PATH = r'D:\\Ultrasound Data\\training'\n",
    "\n",
    "\n",
    "def is_input(filename):\n",
    "    if filename.endswith('_gt'):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "path_structure = path.join(DATASET_PATH, r'*\\*.raw')\n",
    "all_file_paths = glob(path_structure)\n",
    "train_inputs = []\n",
    "train_targets = []\n",
    "\n",
    "for file_path in all_file_paths:\n",
    "    filename = path.basename(file_path).split('.')[0]\n",
    "    if is_input(filename):\n",
    "        train_inputs.append(file_path)\n",
    "    else:\n",
    "        train_targets.append(file_path)\n",
    "        \n",
    "assert len(train_inputs) == len(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ea097a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a8424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
