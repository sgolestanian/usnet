{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475f9bfc-5ff6-41f0-ae9c-1b507fa01db1",
   "metadata": {},
   "source": [
    "# US-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ff132-80eb-48fc-9b88-5797260b1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994cc27-eaa6-46bb-92cb-6e67e46fea62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Camus Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6787f-2581-41cc-ba27-d833faa59ca1",
   "metadata": {},
   "source": [
    "Just to remind myself that \\*.raw and \\*.mhd files contain the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0174e4fc-6db4-42d4-89c0-f1628bcfb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@tf.function\n",
    "def read_raw_image(image_path):\n",
    "    imgfile = tf.io.read_file(image_path)\n",
    "    imgbytes = tf.io.decode_raw(imgfile, out_type=tf.uint8)\n",
    "    img = tf.reshape(imgbytes, (778, 549))\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_raw_seq(image_path):\n",
    "    imgfile = tf.io.read_file(image_path)\n",
    "    imgbytes = tf.io.decode_raw(imgfile, out_type=tf.uint8)\n",
    "    img = tf.reshape(imgbytes, (-1, 778, 549))\n",
    "    return img\n",
    "\n",
    "\n",
    "def play_sequence(sequence_array):\n",
    "    cap = cv2.VideoCapture()\n",
    "    has_frames = True\n",
    "    frame_counter = 0\n",
    "    while True:\n",
    "        frame = sequence_array[frame_counter, :, :]\n",
    "        cv2.imshow('frame',frame)\n",
    "        time.sleep(0.1)\n",
    "        frame_counter+=1\n",
    "        if frame_counter==sequence_array.shape[0]:\n",
    "            frame_counter = 0\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "img = read_raw_image(r'patient0001/patient0001_4CH_ED.raw')\n",
    "plt.imshow(img, 'gray')\n",
    "#play_sequence(seq.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69448390",
   "metadata": {},
   "source": [
    "### Read Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ea62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = read_raw_seq(r'patient0001/patient0001_4CH_sequence.raw')\n",
    "play_sequence(seq.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15304708",
   "metadata": {},
   "source": [
    "Now that we know how to read images and masks, we will process their addresses, and then use tf.data to build the input pipeline. First, we must find the file addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "\n",
    "\n",
    "DATASET_PATH = r'D:\\Ultrasound Data\\training'\n",
    "\n",
    "\n",
    "def data_type(filename):\n",
    "    if filename.endswith('_gt'):\n",
    "        return 'mask'\n",
    "    elif filename.endswith('_sequence'):\n",
    "        return 'sequence'\n",
    "    else:\n",
    "        return 'image'\n",
    "\n",
    "path_structure = path.join(DATASET_PATH, r'*\\*.raw')\n",
    "all_file_paths = glob(path_structure)\n",
    "train_inputs = []\n",
    "image_sequences = []\n",
    "\n",
    "for file_path in all_file_paths:\n",
    "    filename = path.basename(file_path).split('.')[0]\n",
    "    if data_type(filename)=='image':\n",
    "        train_inputs.append(file_path)\n",
    "    elif data_type(filename)=='sequence':\n",
    "        image_sequences.append(file_path)\n",
    "\n",
    "inputs_and_targets = []\n",
    "for input_file in train_inputs:\n",
    "    fpath_no_ext = input_file.split('.')[0]\n",
    "    target_file_path = fpath_no_ext+'_gt.raw'\n",
    "    if not path.exists(target_file_path):\n",
    "        print(f'File not found: {target_file_path}')\n",
    "        continue\n",
    "    else:\n",
    "        inputs_and_targets.append([input_file, target_file_path])\n",
    "assert len(train_inputs) == len(inputs_and_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e705d204",
   "metadata": {},
   "source": [
    "Now we should convert these file addresses to tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b3582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
